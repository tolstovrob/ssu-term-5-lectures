#show heading.where(level: 1): it => {
  pagebreak(weak: true)
  it
}

= Численные методы решения СЛАУ

Метод Гаусса решения СЛАУ появился в 1849 году (на момент 2025 целых 176 лет назад).

== Метод Гаусса. Решение СЛАУ

Рассмотрим СЛАУ следующего вида:

$
  cases(
    a_11 x_1 + a_12 x_2 + ... + a_(1n)x_n = b_1\,,
    a_12 x_1 + a_22 x_2 + ... + a_(2n)x_n = b_2\,,
    ...,
    a_(n 1) x_1 + a_(n 2) x_2 + ... + a_(n n)x_n = b_n\,
  )
$ <raz2:par1:eq1>

или в эквивалентном виде:

$
  mat(a_11, ..., a_(1 n); dots.v, dots.down, dots.v; a_(n 1), ..., a_(n n)) mat(x_1; dots.v; x_n) = mat(b_1; dots.v; b_n),
$ <raz2:par1:eq2>

или в эквивалентном виде через расширенную матрицу коэффициентов (РМК):

$
  mat(
  a_11, dots, a_(1 n), b_1;
  a_21, dots, a_(2 n), b_2;
  dots.v, dots.down, dots.v;
  a_(n 1), dots, a_(n n), b_n; augment: #3)
$ <raz2:par1:eq3>

Далее _будем предполагать_, что СЛАУ *имеет единственное решение*. Метод Гаусса условно разделяют на 2 этапа: прямой и обратный ходы.

Рассмотрим их подробнее.

=== Прямой ход

Сутью прямого хода является эквивалентное преобразование исходной системы к РМК, где все элементы главной диагонли --- единицы, всё что ниже её --- нули, а выше стоят остальные коэффициенты. Так, в самой нижней строке получится:

$
  mat(0, 0, ..., 1, limits(b_n)^tilde; augment: #4)
$

что означает, что в конце СЛАУ будет уравнение вида $x_n = limits(b_n)^tilde$.

Проведём преобразование:

#set math.equation(numbering: none)

$
  & mat(
  a_11, a_12, a_13, dots, a_(1 n), b_1;
  a_21, a_22, a_23, dots, a_(2 n), b_2;
  dots.v, dots.v, dots.v, dots.down, dots.v, dots.v;
  a_(n 1), a_(n 2), a_(n 3), dots, a_(n n), b_n; augment: #5) \
  
  & limits(tilde)^(1 "стр" times 1/a_11, space a_11!=0)

  mat(
  1, a_12^((1)), a_13^((1)), dots, a_(1 n)^((1)), b_1^((1));
  a_21, a_22, a_23, dots, a_(2 n), b_2;
  dots.v, dots.v, dots.v, dots.down, dots.v, dots.v;
  a_(n 1), a_(n 2), a_(n 3), dots, a_(n n), b_n; augment: #5) \

  & limits(tilde)^(2 "стр" - 1 "стр" times a_21)

  mat(
  1, a_12^((1)), a_13^((1)), dots, a_(1 n)^((1)), b_1^((1));
  0, a_22^((1)), a_23^((1)), dots, a_(2 n)^((1)), b_2^((1));
  dots.v, dots.v, dots.v, dots.down, dots.v, dots.v;
  a_(n 1), a_(n 2), a_(n 3), dots, a_(n n), b_n; augment: #5) \

  & limits(tilde)^(3 "стр" - 1 "стр" times a_21) ... \

  & limits(tilde)^(n "стр" - 1 "стр" times a_(n 1))
  
  mat(
  1, a_12^((1)), a_13^((1)), dots, a_(1 n)^((1)), b_1^((1));
  0, a_22^((1)), a_23^((1)), dots, a_(2 n)^((1)), b_2^((1));
  dots.v, dots.v, dots.v, dots.down, dots.v, dots.v;
  0, a_(n 2)^((1)), a_(n 3)^((1)), dots, a_(n n)^((1)), b_n^((1)); augment: #5) \
  
  & limits(tilde)^(2 "стр" times 1/a_22^((1)); a_22 != 0)

  mat(
  1, a_12^((1)), a_13^((1)), dots, a_(1 n)^((1)), b_1^((1));
  0, 1, a_23^((2)), dots, a_(2 n)^((2)), b_2^((2));
  dots.v, dots.v, dots.v, dots.down, dots.v, dots.v;
  0, a_(n 2)^((1)), a_(n 3)^((1)), dots, a_(n n)^((1)), b_n^((1)); augment: #5) \

  & limits(tilde)^(3 "стр" - 2 "стр" times a_31) ... \
  
  & limits(tilde)^(n "стр" - 1 "стр" times a_(n 1)) 
  
  mat(
  1, a_12^((1)), a_13^((1)), dots, a_(1 n)^((1)), b_1^((1));
  0, 1, a_23^((2)), dots, a_(2 n)^((2)), b_2^((2));
  dots.v, dots.v, dots.v, dots.down, dots.v, dots.v;
  0, 0, a_(n 3)^((2)), dots, a_(n n)^((2)), b_n^((2)); augment: #5) \
  
  & limits(tilde)^(3 "стр" times 1/a_33^((1)); a_33 != 0) ... \
  
  & limits(tilde)^(n "стр" times 1/a_(n 1)^((1)); a_(n 2) != 0)

  mat(
  1, a_12^((1)), a_13^((1)), dots, a_(1 n)^((1)), b_1^((1));
  0, 1, a_23^((2)), dots, a_(2 n)^((2)), b_2^((2));
  dots.v, dots.v, dots.v, dots.down, dots.v, dots.v;
  0, 0, 0, dots, a_(n n)^((n)), b_n^((n)); augment: #5).
$

Здесь $k^((n))$ --- это не производная $n$-го порядка, а $k$ после $n$-го преобразования.

Продолжая аналогичные операции, а именно выполняя нормировку следующего диагонального элемента, и обнуляя элементы, стоящие ниже него (построчно), за конечное число шагов придём к РМК следующего вида:

#set math.equation(numbering: "(1)")

$
  mat(
  1, a_12^((1)), a_13^((1)), a_14^((1)), dots, a_(1, n-1)^((1)), a_(1 n)^((1)), b_1^((1));
  0, 1, a_23^((2)), a_24^((2)), dots, a_(2, n-1)^((2)), a_(2 n)^((2)), b_2^((2));
  dots.v, dots.v, dots.v, dots.v, dots.down, dots.v, dots.v, dots.v;
  0, 0, 0, 0, dots, a_(n-1, n)^((n)), a_(n n)^((n)), b_n^((n)); augment: #7) .
$ <raz2:par1:eq4>

=== Обратный ход

Восстанавливаем исходную СЛАУ, которая будет эквивалентна исходой по построению новой РМК:

$
  cases(
    x_11 + & a_12^((1)) x_2 + ... + & a_(1 n)^((1)) = b_1^((1))\,,
    & a_12^((1)) x_2 + ... + & a_(1 n)^((1)) = b_1^((1))\,,
    &...,
    & & a_(n n)^((2)) = b_n^((n)).
  )
$

== Процедура выбора главного (ненулевого) элемента

В предыдущем параграфе мы рассмотрели базовую конструкцию метода Гаусса, в рамках которой в прямом ходе мы попутно делали предположения, что:

+ $a_11 != 0$;
+ $a_22^((2)) != 0$;
+ $a_33^((3)) != 0$; 
+ $a_(n n)^((n - 1)) != 0$.

Если на $k$-ом шаге прямого хода мы встретим $a_(k k)^((k - 1)) eq.triple 0$, или в представлении компьютера $a_(k k)^((k - 1)) in O_delta = (-delta, delta)$

В случаях $(k + 1), ..., n space space a_(m k)^((k - 1)) = limits(max)_(k + 1 lt.eq.slant j lt.eq.slant n) |a_(j k)|$.

+ Если $a_(m k)^((k + 1)) != 0 space ("а в компьютере" in.not (-delta, delta))$, то меняют $k$ и $m$ строки РМК.

Тогда, если в позиции $(k, k)$ $a_(m k)^((k - 1)) != 0$, то меняем *строки* и прямой ход по методу Гаусса может продолжаться.

+ В случае $a_(m k)^((k + 1)) = 0$ ищут элемент $a_(k m)^((k - 1)) = limits(max)_(k + 1 lt.eq.slant j lt.eq.slant n) |a_(k j)|$  

Тогда, если в позиции $(k, m)$ $a_(k m)^(k - 1) != 0$, то меняем местами *столбцы* $k$ и $m$.

В ином случае $(a_(k m)^((k - 1)) = 0)$ прямой ход будет остановлен ввиду невозможности нормировки диагонального элемента.

В случае перестановки столбцов в РМК параллельно необходимо запоминать соответствующую перестановку в векторе $x$, с тем чтобы после завершения уже обратного хода выполнить обратную перестановку этих неизвестных, вернув им натуральный порядок нумерации.

=== Нахождение определителя квадратной матрицы *$A_(n times n)$*.

Для матрицы $A = mat(a_11, a_12; a_21, a_22)$ определитель равен $det A = a_11 a_22 - a_12 a_22$.

С ростом размерности матрицы $A$ число операций для нахождения определителя этой матрицы растёт факториально. В этой связи применим к матрице $A$ процедуру ортогонализации.

Применим эквивалентные преобразования:

+ строка $times 1 / a_(k k)^((k - 1))$;
+ строка + строка $times lambda (!= 0)$;
+ меняются местами строки/столбцы в ПВГЭ

Тогда в отношении определителя:

+ $Delta_m = Delta_(m - 1) times 1 / (a_(k k)^(k - 1)) $;
+ $Delta_m = Delta_(m - 1)$;
+ $Delta_m = - Delta_(m - 1)$

Получаем формулу:

$
  Delta = (-1) times a_11 times a_22^((1)) times ... times a_(n n)^((n - 1)).
$

Отметим, что для того, чтобы воспользоваться формулой, нужно провести предварительную диагонализацию матрицы.
